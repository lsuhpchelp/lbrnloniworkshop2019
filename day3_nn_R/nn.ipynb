{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Demo.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.3.1"
    },
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsuhpchelp/lbrnloniworkshop2019/blob/master/day3_nn_R/nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9M2OON4LMAQ",
        "colab_type": "text"
      },
      "source": [
        "Neural Network with R\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFU3ZdKoe2At",
        "colab_type": "text"
      },
      "source": [
        "# Outline\n",
        "\n",
        "\n",
        "*   **Install and load R packages**\n",
        "\n",
        "*   **`nnet` package**\n",
        "\n",
        "*   **`neuralnet` package**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb40n8LTLWzv",
        "colab_type": "text"
      },
      "source": [
        "# Install and load R packages\n",
        "\n",
        "May take a while on the Colab\n",
        "\n",
        "R packages to be installed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0JBu8ws4N5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "install.packages(\"reshape\")\n",
        "install.packages(\"faraway\")\n",
        "install.packages(\"nnet\")\n",
        "install.packages(\"neuralnet\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND5iRnVkNy8F",
        "colab_type": "text"
      },
      "source": [
        "Load R packages and scripts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GgzeVUcGKQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "library(reshape)\n",
        "library(nnet)\n",
        "library(faraway)\n",
        "library(neuralnet)\n",
        "library(datasets)\n",
        "download.file(\"https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r\",\"nnet_plot_update.r\")\n",
        "source(\"nnet_plot_update.r\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH2MZcenfdKM",
        "colab_type": "text"
      },
      "source": [
        "# 1. `nnet` package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNe3Y5v1ODl9",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 A regression example: `ozone` data\n",
        "* We apply the neural networks to the `ozone` data which was analyzed before using the `nnet` package, due to Venables and Ripley (2002). \n",
        "* `Ozone` data is included in the `faraway` package, which has 330 observations on the following 10 variables. \n",
        "> * **O3** Ozone conc., ppm, at Sandbug AFB.\n",
        "> * **vh** a numeric vector\n",
        ">*  **wind** wind speed\n",
        ">* **humidity** a numeric vector\n",
        ">* **temp** temperature\n",
        ">* **ibh** inversion base height\n",
        ">* **dpg** Daggett pressure gradient\n",
        ">* **ibt** a numeric vector\n",
        ">* **vis** visibility\n",
        ">* **doy** day of the year"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL75lUZAVxoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attach(ozone)\n",
        "summary(ozone)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGqS7orySkSq",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.1 Initial fitting\n",
        "* We started with just **three** variables for simplicity and fit a feed-forward neural network with **one** hidden layer containing **two** units and a linear output. \n",
        "> * Why linear output? This is a regression problem. \n",
        "\n",
        "The result (nnmd1) from will contain # of weights and the initial and final residual sum of squres (RSS, a.k.a. sum of squared errors of prediction (SSE)): "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu7iaf8TVqZ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnmd1 <- nnet(O3~temp+ibh+ibt,ozone,size=2,linout=T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmI2VCrbg5nf",
        "colab_type": "text"
      },
      "source": [
        "* Here we also calculate the total sum of squares:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsQDJJDSS9ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum((O3-mean(O3))^2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko6qQyuicLHt",
        "colab_type": "text"
      },
      "source": [
        "## Quiz\n",
        "1. Why the total weights is 11?  \n",
        "\n",
        "2. Is this neural network model good or not? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr4gAxshjIoj",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.2 Scaling variables\n",
        "* The problems comes from the initial selection of the weights. It is hard to select the initial weights when the variables have very different scales. The solution is to rescale the data to mean zero and unit variance. \n",
        "\n",
        "Check standard deviation before and after the scaling:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhRHc-HJg7uI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "apply(ozone,2,sd)\n",
        "ozone2 <- scale(ozone)\n",
        "apply(ozone2,2,sd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgpBPqQVl1lk",
        "colab_type": "text"
      },
      "source": [
        "Now let's see the new RSS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7v-LRGDmuRk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnmd1 <- nnet(O3~temp+ibh+ibt,ozone2,size=2,linout=T)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D4vLuYFlVLz",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.3 Refitting the model 100 times\n",
        "* Since neural network uses random initial weights, the algorithm may not give the same results for each replication. So we try to refitting the model 100 times using different initial weights and find the best fit of these 100 attempts. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-qKthL5lPeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestrss <- 10000\n",
        "for (i in 1:100){\n",
        "set.seed(i)\n",
        " nnmd1 <- nnet(O3~temp+ibh+ibt,ozone2,size=2,linout=T,trace=F)\n",
        " if (nnmd1$value < bestrss){\n",
        " bestnn <- nnmd1\n",
        " bestrss <- nnmd1$value\n",
        " }\n",
        " }\n",
        "bestnn$value"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgBwyBnPoqLf",
        "colab_type": "text"
      },
      "source": [
        "Summary of bestnn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aaAUTPGopu7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(bestnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3IbrIpIpqyp",
        "colab_type": "text"
      },
      "source": [
        "* The criterion function has 11 weights. The notation `i2 -> h1` above, for example, refers to the link between the second input variable and the first hidden neuron. `b` refers to the bias, which takes a constant value of one. We see that there is one skip-layer connection, `b->o`, from the bias to the output. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgJkK6hhnDKn",
        "colab_type": "text"
      },
      "source": [
        "### 1.1.4 Visualizing the network\n",
        "* `nnet` package does not provide any tool to visualize the network, but some R developer contributed the source code to do that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL116lF_V6Du",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot.nnet(bestnn) # plot function provided by nnet_plot_update.r"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhX-Y0DKnCNx",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "649hPgzNqhNj",
        "colab_type": "text"
      },
      "source": [
        "1. We can put a penalty such as weight decay to obtian a more stable fit. Let's try $\\lambda$ = 0.001\n",
        "\n",
        "Hint: refer to the `nnet` package manaul to find out the options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-dPu4M9V_wz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bestrss <- 10000\n",
        "for (i in 1:100){\n",
        "set.seed(i)\n",
        " nnmd1 <- nnet(O3~temp+ibh+ibt,ozone2,size=2,linout=T, (blanks to be filled here) , trace=F)\n",
        " if (nnmd1$value < bestrss){\n",
        " bestnn <- nnmd1\n",
        " bestrss <- nnmd1$value\n",
        " }\n",
        " }\n",
        " bestnn$value\n",
        " summary(bestnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEXtsg8koIyT",
        "colab_type": "text"
      },
      "source": [
        "We can see the best RSS is somewhat larger than before. This is expected because weight decay sacrifices some fit to the current data to obtain a more stable result. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FuOmmE-s3ou",
        "colab_type": "text"
      },
      "source": [
        "2. Now fit the full dataset using four hidden units sine there are more inputs. \n",
        "> 2.1 Without decay $\\lambda$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMC-XsJfWQ5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estrss <- 10000\n",
        "for (i in 1:100){\n",
        "set.seed(i)\n",
        " nnmd1 <- nnet(O3~ ,    ,    ,   ,)\n",
        " if (nnmd1$value < bestrss){\n",
        " bestnn <- nnmd1\n",
        " bestrss <- nnmd1$value\n",
        " }\n",
        " }\n",
        " bestnn$value\n",
        " summary(bestnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XnHAJ9-tXVb",
        "colab_type": "text"
      },
      "source": [
        ">2.2 With decay $\\lambda$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofx3RTIJsqwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "bestrss <- 10000\n",
        "for (i in 1:100){\n",
        "set.seed(i)\n",
        " nnmd1 <- nnet(O3 ~    ,     ,     ,     ,     )\n",
        " if (nnmd1$value < bestrss){\n",
        " bestnn <- nnmd1\n",
        " bestrss <- nnmd1$value\n",
        " }\n",
        " }\n",
        " bestnn$value\n",
        " summary(bestnn)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Eicq4UuP8A",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Training ozone data with the `caret` package \n",
        "* In R, there is an excellent package `caret` (classification and regression training) which contains functions to streamline the model training process.\n",
        "> * Can train hundreds of models with resampling methods\n",
        "> * Easy to manipulate, well documented\n",
        "> * Will automatically parallelize when multiple cpu cores are registered\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-wRnp6xuA-N",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.1 Install and load the `caret` library\n",
        "\n",
        "It will take a while on the Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC4ciE19WTxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "install.packages(\"caret\")\n",
        "library(caret)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsbIN7qyvgjw",
        "colab_type": "text"
      },
      "source": [
        "### 1.2.2 Main function (`train`) arguments\n",
        "\n",
        "The `train` function set up a grid search on tuning parameters for vaious of data mining methods. \n",
        "* `method` A string specifying which classification or regression model to use. See http://topepo.github.io/caret/train-models-by-tag.html\n",
        "* `tuneGrid` A data frame with possible tuning values. The columns are named the same asthe tuning parameters. see http://topepo.github.io/caret/available-models.html \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELavvk6lWdhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my.grid <- expand.grid(.decay = c(0.0001, 0.001,0.01), .size = c(1, 2, 3,4))\n",
        "nn.model <- train(O3~ .,ozone2,method=\"nnet\",tuneGrid = my.grid,trace=F)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcaGOYeywh7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_45gCAXZXYUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(nn.model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA1BzgOmv2sw",
        "colab_type": "text"
      },
      "source": [
        "## 2. `neuralnet` package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HH4MiJTwxnK",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 A classification example: `Infertility` data\n",
        "* We apply the neural networks to the `Infertility` data using the `neuralnet` package. \n",
        "* `Infertility` data is included in the `datasets` package, which has 248 observations on the following 8 variables. \n",
        "> * **case** case status is the response, a binary variable with 1 = case and 0 = control\n",
        "> * **age** age in years of case\n",
        ">*  **parity** count\n",
        ">* **education** 0 = 1-5 years 1 = 6-11 years 2 = 12+ years\n",
        ">* **spontaneous**  number of prior spontaneous abortions 0 = 0, 1 = 1, 2 = 2 or more\n",
        ">* **induced** number of prior induced abortions 0 = 0, 1 = 1, 2 = 2 or more\n",
        ">* **stratum**  a numeric vector\n",
        ">* **pooled.stratum** a numeric vector \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOZFq7VwQKAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "library(reshape)\n",
        "library(faraway)\n",
        "library(neuralnet)\n",
        "library(datasets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdJNl5GDTGN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "str(infert)\n",
        "table(infert$case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USHZGUy80YAj",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.1 Training Set and Test Set\n",
        "\n",
        "* Dataset could be randomly split into two parts: training set and test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKVarCoRzxgH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set.seed(1)\n",
        "indx <- sample(1:248,size=248,replace=F)\n",
        "dat1 <- infert[indx[1:200],] #train set\n",
        "dat2 <- infert[indx[201:248],] #test set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpK6ambNTgZq",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.2 Main function (`neuralnet`) arguments\n",
        "* `hidden` a vector of integers specifying the number of hidden neurons (vertices) in each layer.\n",
        "* `threshold` a  vector about the threshold for the partial derivatives of the errorfunction as stopping criteria.\n",
        "* `algorithm` a string containing the algorithm type to calculate the neural network.\n",
        "* `err.fct` the error function, which is a differentiable function that is used for the calculation of the error.  Alterna-tively, the strings ’sse’ and ’ce’ which stand for the sum of squared errors andthe cross-entropy can be used.\n",
        "* `act.fct` the activation function, which is a differentiable function that is used for smoothing the result of the cross productof the covariate or neurons and the weights.  Additionally the strings, ’logistic’and ’tanh’ are possible for the logistic function and tangent hyperbolicus.\n",
        "* `linear.output` logical. If act.fct should not be applied to the output neurons set linear output toTRUE, otherwise to FALSE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKdptCEFV2XQ",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.3 Model fitting\n",
        "* We started with **four** variables and fit a feed-forward neural network with **one** hidden layer containing **four** units. \n",
        "* The error function is cross-entropy (`err.fct=\"ce\"`) since this is a classification problem. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us9N39fCT8KW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set.seed(2)\n",
        "nn <- neuralnet(case~age+parity+induced+spontaneous,data=dat1,hidden=4,err.fct=\"ce\",linear.output=FALSE)\n",
        "nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQUllJE5kwjr",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.4 Training set result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoYRv4lbU1JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out <- cbind(nn$covariate,nn$net.result[[1]])\n",
        "dimnames(out) <- list(NULL,c(\"age\",\"parity\",\"induced\",\"spontaneous\",\"nn-output\"))\n",
        "head(out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFpKfTvDkxDZ",
        "colab_type": "text"
      },
      "source": [
        "### 2.1.5 Visualizing the network\n",
        "* `neuralnet` package's own `plot` function is designed for an inspection of the weights for objectsof class `nn` any tool to visualize the network, but some R developer contributed the source code to do that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9E6G6zsVApn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot(nn, rep=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkHTUFKqpnb6",
        "colab_type": "text"
      },
      "source": [
        "## Exercise 2\n",
        "1. Test the accuracy of the model with the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFW4OtQCsRt7",
        "colab_type": "text"
      },
      "source": [
        "1.1 Choose four variables from the test data\n",
        "\n",
        "use `subset` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHUy6VxMqc5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_test <- subset(dat2, select = c(\"age\",\"parity\",\"induced\",\"spontaneous\"))\n",
        "head(temp_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv13iKGn0e87",
        "colab_type": "text"
      },
      "source": [
        "Or use indexing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3bvjrbD01c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "head(dat2)  # find the indices\n",
        "temp_test <- dat2[,c(2:4,6)]\n",
        "head(temp_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1RbF_ZtsybS",
        "colab_type": "text"
      },
      "source": [
        "1.2 `neuralnet` package's own `compute` function is designed to compute the prediction variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE5mnfxks07C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.results <- compute(nn, temp_test)\n",
        "head(nn.results$net.result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB6VYe2Qs1eh",
        "colab_type": "text"
      },
      "source": [
        "1.3 Compare the predicted result to the actual result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB3FCZCjs3na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results <- data.frame(actual = dat2$case, prediction = nn.results$net.result)\n",
        "results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT0kt27Gs3zk",
        "colab_type": "text"
      },
      "source": [
        "1.4 Misclassification table\n",
        "Build a confusion matrix: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsFmO0sKs5v4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "roundedresults<-sapply(results,round,digits=0)\n",
        "roundedresultsdf=data.frame(roundedresults)\n",
        "attach(roundedresultsdf)\n",
        "table(actual,prediction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfX9Q5LZqdQ5",
        "colab_type": "text"
      },
      "source": [
        "2. Build a two-layer model. The first layer has two hidden units while the second has three"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDYIdi9xq72L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set.seed(2)\n",
        "nn2 <- neuralnet(case~age+parity+induced+spontaneous,data=dat1,hidden=    ,err.fct=\"ce\",linear.output=FALSE)\n",
        "plot(nn2, rep=\"best\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZHNXS8tqHrf",
        "colab_type": "text"
      },
      "source": [
        "# Getting Help\n",
        "\n",
        "* Documentation: http://www.hpc.lsu.edu/docs\n",
        "* Contact us\n",
        "> * Email ticket system: sys-help@loni.org\n",
        "> * Telephone Help Desk: 225-578-0900\n",
        "\n"
      ]
    }
  ]
}